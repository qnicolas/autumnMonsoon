{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5M_PATH  = \"/global/homes/w/wboos/m3310project/wboos/era5monthlyQuentin/\"\n",
    "ERA5M_PATH2 = \"/global/project/projectdirs/m3310/wboos/era5monthly/\"\n",
    "\n",
    "boxNH = [[-100, -70, 12 , 20],\n",
    "         [-80 , -60, 8  , 16],\n",
    "         [70  , 90 , 2  , 18],\n",
    "         [100 , 120, 8  , 20],\n",
    "         [118 , 140, 4  , 20],\n",
    "         [100 , 110, 0  , 12],\n",
    "        ]\n",
    "\n",
    "boxSH = [[20  , 50 , -20, 0 ],\n",
    "         [-60 , -30, -20, 0 ],\n",
    "        ]\n",
    "\n",
    "boxNH1 = [[b[0]%360,b[1]%360,b[2],b[3]] for b in boxNH]\n",
    "boxSH1 = [[b[0]%360,b[1]%360,b[2],b[3]] for b in boxSH]\n",
    "\n",
    "namesNH = [\"Central America\",\n",
    "           \"Venezuela\",\n",
    "           \"South India / Sri Lanka\",\n",
    "           \"Vietnam / South China Sea\",\n",
    "           \"Philippines\",\n",
    "           \"Malaysia\"\n",
    "          ]\n",
    "namesSH = [\"Tanzania\",\n",
    "           \"NorthEast Brazil\"\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extraction from ERA5\n",
    "era5yrs = list(range(1979,2019))\n",
    "\n",
    "def retrieve_era5(year,varid):\n",
    "    \"\"\"gather an ERA5 monthly mean variable for the year 'year'\n",
    "    varid gives the id of the variable in era5\n",
    "        - year : str, \"YYYY\"\n",
    "        - varid : str, eg. \"128_130_t\" for temperature\n",
    "    \"\"\"\n",
    "    era5var = xr.open_dataset(glob.glob(os.path.join(ERA5M_PATH,\"*/e5.*.%s.*.%s*.nc\"%(varid,year)))[0])\n",
    "    varname = list(era5var.data_vars)[0] #get name of the main variable, eg 'T' for temperature\n",
    "    \n",
    "    return era5var[varname]\n",
    "\n",
    "def retrieve_era5_month(month,varid):\n",
    "    varlist = []\n",
    "    for year in era5yrs:\n",
    "        var = retrieve_era5(year,varid)\n",
    "        varmonth = var.sel(time=\"%s-%s\"%(year,month))\n",
    "        varlist.append(varmonth)\n",
    "    return xr.concat(varlist, \"time\")\n",
    "\n",
    "#climatological mean computation\n",
    "def climat_mean(month,varid):\n",
    "    \"\"\"Compute the climatological mean of a variable specified by 'varid', for a specific month\n",
    "        - month : str, eg. '05' for May\n",
    "        - varid : str, eg. \"128_130_t\" for temperature\n",
    "    \"\"\"    \n",
    "    return retrieve_era5_month(month,varid).mean(\"time\")\n",
    "\n",
    "\n",
    "def region_mean2D(variable,mask,box):\n",
    "    \"\"\"Given a 2D variable (lat, lon), compute a spatial mean within a specified region\n",
    "    defined by a mask, inside a given box\n",
    "        - variable = 3D xarray.dataarray. Dimensions must be named \"latitude\" and \"longitude\"\n",
    "        - mask = 2D xarray.dataarray of 0s and 1s. Must have same grid and dimension names as 'variable'\n",
    "        - box = list of four items, [lon1, lon2, lat1, lat2]\n",
    "    \"\"\"\n",
    "    mask_box = mask.sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2]))\n",
    "    variable_box = variable.sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2]))\n",
    "    maskedvar = variable_box*mask_box\n",
    "    region_mean = maskedvar.fillna(0).sum([\"latitude\",\"longitude\"])/ mask_box.sum([\"latitude\",\"longitude\"])\n",
    "    \n",
    "    return region_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAPE_from_skewT(temp,rh):\n",
    "    \"\"\"Compute CAPE given a vertical profile of temperature and relative humidity\"\"\"\n",
    "    p = np.array(temp.level)* units.hPa\n",
    "    T = (np.array(temp)-273.15) * units.degC\n",
    "    r = np.array(rh)/100\n",
    "    Td = mpcalc.dewpoint_from_relative_humidity(T,r)\n",
    "    \n",
    "    # Calculate the profile of a parcel lifted from the surface\n",
    "    prof = mpcalc.parcel_profile(p[::-1], T[-1], Td[-1]).to('degC')[::-1]\n",
    "    \n",
    "    #compute cape\n",
    "    cape,_=mpcalc.cape_cin(p[::-1],T[::-1],Td[::-1],prof[::-1])\n",
    "\n",
    "    return cape/units('J/kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_coord(mask):\n",
    "    \"\"\"Switch the longitude coord from (-180,180) to (0,360) \n",
    "    and change coordinate names from 'LAT1','LON1' to 'latitude' and 'longitude'\"\"\"\n",
    "    mask0=mask.copy()\n",
    "    mask0.coords['longitude'] = mask0.coords['LON1']%360\n",
    "    mask1 = mask0.swap_dims({'LON1': 'longitude'}).rename({'LAT1': 'latitude'})\n",
    "\n",
    "    #Sort the longitude values\n",
    "    sort_inds = {\"longitude\": np.argsort(mask1[\"longitude\"].values)}\n",
    "    mask1 = mask1.isel(**sort_inds)\n",
    "    return mask1\n",
    "\n",
    "#masks = xr.open_dataset(\"/global/cscratch1/sd/qnicolas/autumnMonsoonData/winter_rainfall_masks.nc\")\n",
    "masks = xr.open_dataset(\"winter_rainfall_masks.nc\")\n",
    "trmm_nh_winter_mask = masks.TRMM_NH_WINTER_MASK.fillna(0.)\n",
    "trmm_sh_winter_mask = masks.TRMM_SH_WINTER_MASK.fillna(0.)\n",
    "\n",
    "REFERENCE_GRID = xr.open_dataset(ERA5M_PATH+\"e5.moda.an.pl/e5.moda.an.pl.128_060_pv.ll025sc.1979010100_1979120100.nc\").PV.sel(latitude=slice(50., -50.)).isel(time=0) #to get the era5 grid\n",
    "\n",
    "trmm_nh_winter_mask1 = (slide_coord(trmm_nh_winter_mask).interp_like(REFERENCE_GRID) > 0)*1.\n",
    "trmm_sh_winter_mask1 = (slide_coord(trmm_sh_winter_mask).interp_like(REFERENCE_GRID) > 0)*1.                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmask = xr.open_dataset(\"/global/cfs/projectdirs/m3522/cmip6/ERA5/e5.oper.invariant/197901/e5.oper.invariant.128_172_lsm.ll025sc.1979010100_1979010100.nc\").LSM.isel(time=0)\n",
    "landmask50=landmask.interp_like(REFERENCE_GRID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghcn = xr.open_dataset(\"/global/cscratch1/sd/qnicolas/ghcn.precip.mon.total.nc\",decode_times=False)\n",
    "ghcn.coords['time'] = pd.to_datetime('1800-01-01') + pd.to_timedelta(np.array(ghcn.coords['time']),'d')\n",
    "ghcn=ghcn.rename({'lat':'latitude','lon':'longitude'}).precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine dry and wet years for each region,with ghcn\n",
    "def timesel(year,month,targetmonth):\n",
    "    return (year >= 1979) & (year < 2019) & (month == targetmonth)\n",
    "\n",
    "ghcn_nov = ghcn.sel(time = timesel(ghcn['time.year'],ghcn['time.month'],11))\n",
    "ghcn_may = ghcn.sel(time = timesel(ghcn['time.year'],ghcn['time.month'],5))\n",
    "\n",
    "nwettest = int((2015-1979)/3);ndriest = nwettest\n",
    "drywetyearsNH = []\n",
    "for i,box in enumerate(boxNH1):\n",
    "    ghcn_nov_box = np.array([region_mean2D(ghcn_nov.sel(latitude=slice(50., -50.),time=y),\n",
    "                                           trmm_nh_winter_mask1.interp_like(ghcn_nov),box) for y in ghcn_nov.time])\n",
    "    drywetyearsNH.append({\"dry\" : ghcn_nov.time[np.argpartition(ghcn_nov_box, ndriest)[:ndriest]], \"wet\" : ghcn_nov.time[np.argpartition(-ghcn_nov_box, nwettest)[:nwettest]]})\n",
    "\n",
    "drywetyearsSH = []\n",
    "for i,box in enumerate(boxSH1):\n",
    "    ghcn_may_box = np.array([region_mean2D(ghcn_may.sel(latitude=slice(50., -50.),time=y),\n",
    "                                           trmm_sh_winter_mask1.interp_like(ghcn_may),box) for y in ghcn_may.time])\n",
    "    drywetyearsSH.append({\"dry\" : ghcn_may.time[np.argpartition(ghcn_may_box, ndriest)[:ndriest]], \"wet\" : ghcn_may.time[np.argpartition(-ghcn_may_box, nwettest)[:nwettest]]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374.509877204895\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "all_tt_nov = retrieve_era5_month(\"11\",'128_130_t' );all_tt_may = retrieve_era5_month(\"05\",'128_130_t' )\n",
    "all_rh_nov = retrieve_era5_month(\"11\",'128_157_r' );all_rh_may = retrieve_era5_month(\"05\",'128_157_r' )\n",
    "print(time.time()-t)#takes ~6min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cape_nov = retrieve_era5_month(\"11\",'128_059_cape' );all_cape_may = retrieve_era5_month(\"05\",'128_059_cape' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tt_nov = all_tt_nov.mean(\"time\");mean_tt_may = all_tt_may.mean(\"time\")\n",
    "mean_rh_nov = all_rh_nov.mean(\"time\");mean_rh_may = all_rh_may.mean(\"time\")\n",
    "mean_cape_nov = all_cape_nov.mean(\"time\");mean_cape_may = all_cape_may.mean(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.99146437644958\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "ttNH = []; rhNH = []; capeNH = [] #Global mean quantities for the dry and wet years corresponding to each region\n",
    "for i,box in enumerate(boxNH1):\n",
    "    ttNH.append(  {\"dry\" : all_tt_nov.sel(time=drywetyearsNH[i][\"dry\"]).mean(\"time\")  , \"wet\" : all_tt_nov.sel(time=drywetyearsNH[i][\"wet\"]).mean(\"time\")  })\n",
    "    rhNH.append(  {\"dry\" : all_rh_nov.sel(time=drywetyearsNH[i][\"dry\"]).mean(\"time\")  , \"wet\" : all_rh_nov.sel(time=drywetyearsNH[i][\"wet\"]).mean(\"time\")  }) \n",
    "    capeNH.append({\"dry\" : all_cape_nov.sel(time=drywetyearsNH[i][\"dry\"]).mean(\"time\"), \"wet\" : all_cape_nov.sel(time=drywetyearsNH[i][\"wet\"]).mean(\"time\")}) \n",
    "\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.15903902053833\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "ttSH = []; rhSH = []; capeSH = []\n",
    "for i,box in enumerate(boxSH1):\n",
    "    ttSH.append(  {\"dry\" : all_tt_may.sel(time=drywetyearsSH[i][\"dry\"]).mean(\"time\")  , \"wet\" : all_tt_may.sel(time=drywetyearsSH[i][\"wet\"]).mean(\"time\")  })\n",
    "    rhSH.append(  {\"dry\" : all_rh_may.sel(time=drywetyearsSH[i][\"dry\"]).mean(\"time\")  , \"wet\" : all_rh_may.sel(time=drywetyearsSH[i][\"wet\"]).mean(\"time\")  }) \n",
    "    capeSH.append({\"dry\" : all_cape_may.sel(time=drywetyearsSH[i][\"dry\"]).mean(\"time\"), \"wet\" : all_cape_may.sel(time=drywetyearsSH[i][\"wet\"]).mean(\"time\")}) \n",
    "\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        \u001b[1mMay (SH)/ November(NH) CAPE values in J/kg\u001b[0m\n",
      "Region                       ERA5, mean 1979-2018    ERA5, dry yrs    ERA5, wet years    CAPE from mean sounding 1979-2018\n",
      "-------------------------  ----------------------  ---------------  -----------------  -----------------------------------\n",
      "NorthEast Brazil                           331.71           320.61             336.16                               552.47\n",
      "Tanzania                                   413.19           357.76             477.88                               576.88\n",
      "Vietnam / South China Sea                  444.48           446.45             433.87                               347.01\n",
      "South India / Sri Lanka                    454.2            445.1              474.89                               726.14\n",
      "Malaysia                                   605.66           623.49             550.21                              1063.44\n",
      "Philippines                                640.37           637.71             686                                  925.59\n",
      "Central America                            716.6            808.81             642.09                               818.33\n",
      "Venezuela                                  849.79           905.6              790.65                              1210.81\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(' '*40+'\\033[1m'+ \"May (SH)/ November(NH) CAPE values in J/kg\" + '\\033[0m')\n",
    "\n",
    "tab=[]\n",
    "\n",
    "for i,box in enumerate(boxNH1):\n",
    "    cape_era5_mean = region_mean2D(mean_cape_nov, trmm_nh_winter_mask1, box)\n",
    "    cape_era5_dry =  region_mean2D(capeNH[i][\"dry\"], trmm_nh_winter_mask1, box)\n",
    "    cape_era5_wet =  region_mean2D(capeNH[i][\"wet\"], trmm_nh_winter_mask1, box)\n",
    "    cape_skewT_mean = CAPE_from_skewT(region_mean2D(mean_tt_nov, trmm_nh_winter_mask1, box),region_mean2D(mean_rh_nov, trmm_nh_winter_mask1, box))\n",
    "    \n",
    "    tab.append([namesNH[i], \"%.2f\"%cape_era5_mean, \"%.2f\"%cape_era5_dry, \"%.2f\"%cape_era5_wet, \"%.2f\"%cape_skewT_mean])\n",
    "\n",
    "for i,box in enumerate(boxSH1):\n",
    "    cape_era5_mean = region_mean2D(mean_cape_may, trmm_sh_winter_mask1, box)\n",
    "    cape_era5_dry =  region_mean2D(capeSH[i][\"dry\"], trmm_sh_winter_mask1, box)\n",
    "    cape_era5_wet =  region_mean2D(capeSH[i][\"wet\"], trmm_sh_winter_mask1, box)\n",
    "    cape_skewT_mean = CAPE_from_skewT(region_mean2D(mean_tt_may, trmm_sh_winter_mask1, box),region_mean2D(mean_rh_may, trmm_sh_winter_mask1, box))\n",
    "    \n",
    "    tab.append([namesSH[i], \"%.2f\"%cape_era5_mean, \"%.2f\"%cape_era5_dry, \"%.2f\"%cape_era5_wet, \"%.2f\"%cape_skewT_mean])\n",
    "\n",
    "tab.sort(key=lambda l : float(l[1]))\n",
    "    \n",
    "print(tabulate(tab, headers=['Region'+' '*17, 'ERA5, mean 1979-2018', 'ERA5, dry yrs','ERA5, wet years','CAPE from mean sounding 1979-2018']))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OND and AMJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selseason(month,monthinf,monthsup):\n",
    "    return (np.mod(month - monthinf,12) < np.mod(monthsup - monthinf,12)) & (np.mod(monthsup - month,12) <= np.mod(monthsup - monthinf,12))\n",
    "\n",
    "def retrieve_era5_season(monthinf,monthsup,varid):\n",
    "    varlist = []\n",
    "    for year in era5yrs:\n",
    "        var = retrieve_era5(year,varid)\n",
    "        varmonth = var.sel(time=selseason(var['time.month'],monthinf,monthsup)).mean('time')\n",
    "        varlist.append(varmonth)\n",
    "    return xr.concat(varlist, \"time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732.9126734733582\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "all_tt_ond = retrieve_era5_season(10,1,'128_130_t' );all_tt_amj = retrieve_era5_season(4,7,'128_130_t' )\n",
    "all_rh_ond = retrieve_era5_season(10,1,'128_157_r' );all_rh_amj = retrieve_era5_season(4,7,'128_157_r' )\n",
    "all_cape_ond = retrieve_era5_season(10,1,'128_059_cape' );all_cape_amj = retrieve_era5_season(4,7,'128_059_cape' )\n",
    "print(time.time()-t)#takes ~12min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_tt_ond['time']   = all_cape_nov.time; all_tt_amj['time']   = all_cape_may.time\n",
    "all_rh_ond['time']   = all_cape_nov.time; all_rh_amj['time']   = all_cape_may.time\n",
    "all_cape_ond['time'] = all_cape_nov.time; all_cape_amj['time'] = all_cape_may.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tt_ond = all_tt_ond.mean(\"time\");mean_tt_amj = all_tt_amj.mean(\"time\")\n",
    "mean_rh_ond = all_rh_ond.mean(\"time\");mean_rh_amj = all_rh_amj.mean(\"time\")\n",
    "mean_cape_ond = all_cape_ond.mean(\"time\");mean_cape_amj = all_cape_amj.mean(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.52869939804077\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "ttNH_season = []; rhNH_season = []; capeNH_season = [] #Global mean quantities for the dry and wet years corresponding to each region\n",
    "for i,box in enumerate(boxNH1):\n",
    "    ttNH_season.append(  {\"dry\" :   all_tt_ond.sel(time=np.in1d(all_tt_ond['time.year'],drywetyearsNH[i][\"dry\"][\"time.year\"])).mean(\"time\")  , \"wet\" :    all_tt_ond.sel(time=np.in1d(all_tt_ond['time.year'],drywetyearsNH[i][\"wet\"][\"time.year\"])).mean(\"time\")  })\n",
    "    rhNH_season.append(  {\"dry\" :   all_rh_ond.sel(time=np.in1d(all_rh_ond['time.year'],drywetyearsNH[i][\"dry\"][\"time.year\"])).mean(\"time\")  , \"wet\" :    all_rh_ond.sel(time=np.in1d(all_rh_ond['time.year'],drywetyearsNH[i][\"wet\"][\"time.year\"])).mean(\"time\")  }) \n",
    "    capeNH_season.append({\"dry\" : all_cape_ond.sel(time=np.in1d(all_cape_ond['time.year'],drywetyearsNH[i][\"dry\"][\"time.year\"])).mean(\"time\"), \"wet\" :  all_cape_ond.sel(time=np.in1d(all_cape_ond['time.year'],drywetyearsNH[i][\"wet\"][\"time.year\"])).mean(\"time\")}) \n",
    "\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.483721017837524\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "ttSH_season = []; rhSH_season = []; capeSH_season = [] #Global mean quantities for the dry and wet years corresponding to each region\n",
    "for i,box in enumerate(boxSH1):\n",
    "    ttSH_season.append(  {\"dry\" :   all_tt_amj.sel(time=np.in1d(all_tt_amj['time.year'],drywetyearsSH[i][\"dry\"][\"time.year\"])).mean(\"time\")  , \"wet\" :    all_tt_amj.sel(time=np.in1d(all_tt_amj['time.year'],drywetyearsSH[i][\"wet\"][\"time.year\"])).mean(\"time\")  })\n",
    "    rhSH_season.append(  {\"dry\" :   all_rh_amj.sel(time=np.in1d(all_rh_amj['time.year'],drywetyearsSH[i][\"dry\"][\"time.year\"])).mean(\"time\")  , \"wet\" :    all_rh_amj.sel(time=np.in1d(all_rh_amj['time.year'],drywetyearsSH[i][\"wet\"][\"time.year\"])).mean(\"time\")  }) \n",
    "    capeSH_season.append({\"dry\" : all_cape_amj.sel(time=np.in1d(all_cape_amj['time.year'],drywetyearsSH[i][\"dry\"][\"time.year\"])).mean(\"time\"), \"wet\" :  all_cape_amj.sel(time=np.in1d(all_cape_amj['time.year'],drywetyearsSH[i][\"wet\"][\"time.year\"])).mean(\"time\")}) \n",
    "\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        \u001b[1mAMJ (SH)/ OND(NH) CAPE values in J/kg\u001b[0m\n",
      "Region                       ERA5, mean 1979-2018    ERA5, dry yrs    ERA5, wet years    CAPE from mean sounding 1979-2018\n",
      "-------------------------  ----------------------  ---------------  -----------------  -----------------------------------\n",
      "NorthEast Brazil                           331.21           315.84             345.83                               509.1\n",
      "Vietnam / South China Sea                  425.04           415.47             416.19                               219.58\n",
      "Tanzania                                   431.19           397.47             475.19                               469.68\n",
      "South India / Sri Lanka                    496.72           490.9              512.51                               680.44\n",
      "Malaysia                                   598.21           593.07             576.46                               974.54\n",
      "Philippines                                599.64           580.56             632.08                               757.26\n",
      "Central America                            762.59           829.66             671.39                               836.11\n",
      "Venezuela                                  864              898.7              783.75                              1114.23\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(' '*40+'\\033[1m'+ \"AMJ (SH)/ OND(NH) CAPE values in J/kg\" + '\\033[0m')\n",
    "\n",
    "tab=[]\n",
    "\n",
    "for i,box in enumerate(boxNH1):\n",
    "    cape_era5_mean = region_mean2D(mean_cape_ond, trmm_nh_winter_mask1, box)\n",
    "    cape_era5_dry =  region_mean2D(capeNH_season[i][\"dry\"], trmm_nh_winter_mask1, box)\n",
    "    cape_era5_wet =  region_mean2D(capeNH_season[i][\"wet\"], trmm_nh_winter_mask1, box)\n",
    "    cape_skewT_mean = CAPE_from_skewT(region_mean2D(mean_tt_ond, trmm_nh_winter_mask1, box),region_mean2D(mean_rh_ond, trmm_nh_winter_mask1, box))\n",
    "    \n",
    "    tab.append([namesNH[i], \"%.2f\"%cape_era5_mean, \"%.2f\"%cape_era5_dry, \"%.2f\"%cape_era5_wet, \"%.2f\"%cape_skewT_mean])\n",
    "\n",
    "for i,box in enumerate(boxSH1):\n",
    "    cape_era5_mean = region_mean2D(mean_cape_amj, trmm_sh_winter_mask1, box)\n",
    "    cape_era5_dry =  region_mean2D(capeSH_season[i][\"dry\"], trmm_sh_winter_mask1, box)\n",
    "    cape_era5_wet =  region_mean2D(capeSH_season[i][\"wet\"], trmm_sh_winter_mask1, box)\n",
    "    cape_skewT_mean = CAPE_from_skewT(region_mean2D(mean_tt_amj, trmm_sh_winter_mask1, box),region_mean2D(mean_rh_amj, trmm_sh_winter_mask1, box))\n",
    "    \n",
    "    tab.append([namesSH[i], \"%.2f\"%cape_era5_mean, \"%.2f\"%cape_era5_dry, \"%.2f\"%cape_era5_wet, \"%.2f\"%cape_skewT_mean])\n",
    "\n",
    "tab.sort(key=lambda l : float(l[1]))\n",
    "\n",
    "print(tabulate(tab, headers=['Region'+' '*17, 'ERA5, mean 1979-2018', 'ERA5, dry yrs','ERA5, wet years','CAPE from mean sounding 1979-2018']))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERA5",
   "language": "python",
   "name": "era5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
